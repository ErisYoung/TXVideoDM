{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import requests as rq\n",
    "from copyheaders import headers_raw_to_dict\n",
    "\n",
    "headers=b\"\"\"\n",
    "user-agent: Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36\n",
    "\"\"\"\n",
    "\n",
    "headers=headers_raw_to_dict(headers)\n",
    "\n",
    "def get_one_page_barrage(url,headers):\n",
    "    \"\"\"\n",
    "    爬取对应url的弹幕信息\n",
    "    \"\"\"\n",
    "    html=rq.get(url,headers=headers)\n",
    "    text=html.text\n",
    "    start_index=text.find(\"{\")\n",
    "    json_data=json.loads(text[start_index:-1],strict=False)\n",
    "    columns=['用户名','内容','会员等级','评论时间点','评论点赞数','评论id']\n",
    "    df=pd.DataFrame(columns=columns)\n",
    "    for item in json_data['comments']:\n",
    "        content = item['content']  #弹幕内容\n",
    "        name = item['opername']    #用户名\n",
    "        upcount = item['upcount']  #点赞数\n",
    "        user_degree =item['uservip_degree'] #会员等级\n",
    "        timepoint = item['timepoint']  #发布时间\n",
    "        comment_id = item['commentid']  #弹幕ID\n",
    "        temp=pd.Series([name,content,user_degree,timepoint,upcount,comment_id],index=columns)\n",
    "        df=df.append(temp,ignore_index=True)\n",
    "    return df \n",
    "\n",
    "def parse_epid(headers):\n",
    "    \"\"\"\n",
    "    获取每集的id和其他属性\n",
    "    \"\"\"\n",
    "    url1='https://union.video.qq.com/fcgi-bin/data?otype=json&tid=682&appid=20001238&appkey=6c03bbe9658448a4&idlist=x003061htl5,t00306i1e62,x003061htl5,b0030velala,w0030ilim7z,i0030r7v63u,z003044noq2,m0030sfinyr,c0030u884k7,k0030m5zbr7,l0030e5nglm,h0030b060vn,j003090ci7w,n0030falyoi,s00308u9kwx,p0030fohijf,g00303ob0cx,v0030960y6n,x0030bl84xw,v0030keuav1,t0030kups1i,n0030y2o52i,x0030s52mev,d0030xuekgw,o0030md1a2a,x0030peo3sk,d00303l5j4k,t0030aexmnt,a0030ybi45z,y0030wpe2wu&callback=jQuery19102114742155319942_1555398342372&_=1555398342375'\n",
    "    url2='https://union.video.qq.com/fcgi-bin/data?otype=json&tid=682&appid=20001238&appkey=6c03bbe9658448a4&idlist=t0030epjqsi,g003035mi84,n00301fxqbh,h0030zivlrq,d0030qc1yu2,m0030q9ywxj,h0030j0eq19,j0030jks835,a00308xw434,l0030tb319m,x0030xogl32,g0030fju3w3,a0030vrcww0,l0030jzi1mi,c0030mq8yjr,u00302fdo8v,a0030w9g57k,n0030wnj6i8,j0030h91ouj,j00304eu73n,t00305kc1f5,i0030x490o2,u0030jtmlj2,d003031ey5h,w0850w594k6,l0854pfn9lg,f08546r7l7a,d0854s0oq1z,m08546pcd9k,p0854r1nygj&callback=jQuery19102114742155319942_1555398342367&_=1555398342376'\n",
    "    columns=['id','title','播放量','集号']\n",
    "    df=pd.DataFrame(columns=columns)\n",
    "    \n",
    "    for url in [url1,url2]:\n",
    "        html=rq.get(url,headers)\n",
    "        text=html.text\n",
    "        json_data=json.loads(text[text.find(\"{\"):-1])\n",
    "        for item in json_data['results']:\n",
    "            video_id=item['id']\n",
    "            title=item['fields']['title']\n",
    "            view_counts=item['fields']['view_all_count']\n",
    "            episode=int(item['fields']['episode'])\n",
    "            if episode==0:\n",
    "                pass\n",
    "            else:\n",
    "                temp=pd.Series([video_id,title,view_counts,episode],index=columns)\n",
    "                df=df.append(temp,ignore_index=True)\n",
    "                \n",
    "    df=df.drop_duplicates(['id'])\n",
    "    return df.sort_values(\"集号\").reset_index(drop=True)\n",
    "\n",
    "def parse_targetId_by_vId(vId,headers):\n",
    "    \"\"\"\n",
    "    对于每个vid，获取其对应的target_id\n",
    "    \"\"\"\n",
    "    base_url='https://access.video.qq.com/danmu_manage/regist?vappid=97767206&vsecret=c0bdcbae120669fff425d0ef853674614aa659c605a613a4&raw=1'\n",
    "    payload={\"wRegistType\":2,\"vecIdList\":[vId],\n",
    "       \"wSpeSource\":0,\"bIsGetUserCfg\":1,\n",
    "       \"mapExtData\":{vId:{\"strCid\":\"wu1e7mrffzvibjy\",\"strLid\":\"\"}}}\n",
    "    \n",
    "    html=rq.post(base_url,data=json.dumps(payload),headers=headers)\n",
    "    json_data=json.loads(html.text)\n",
    "    target_id_str=json_data['data']['stMap'][vId]['strDanMuKey']\n",
    "    target_id=target_id_str[target_id_str.find(\"targetid=\")+9:target_id_str.find(\"vid\")-1]\n",
    "    return (vId,target_id)\n",
    "\n",
    "def get_all_danmukey():\n",
    "    \"\"\"\n",
    "    爬取所有target_id 与 v_id的映射\n",
    "    \"\"\"\n",
    "    df=parse_epid(headers)\n",
    "    info_lists=[]\n",
    "    for i in df['id']:\n",
    "        info=parse_targetId_by_vId(i,headers)\n",
    "        if info:\n",
    "            info_lists.append(info)\n",
    "            time.sleep(0.5+random.random())\n",
    "    \n",
    "    columns=['v_id','target_id']\n",
    "    df_id=pd.DataFrame(info_lists,columns=columns)\n",
    "    \n",
    "    merged_df=pd.merge(df,df_id,left_on=\"id\",right_on=\"v_id\",how=\"inner\") \n",
    "    return merged_df\n",
    "\n",
    "def parse_urls(v_id,target_id,page):\n",
    "    \"\"\"\n",
    "    format初始url\n",
    "    \"\"\"\n",
    "    base_url=\"https://mfm.video.qq.com/danmu?otype=json&callback=jQuery1910029789363731311136_1555394558009&timestamp={page}&target_id={target_id}%26vid%3D{v_id}&count=80\" \n",
    "    for i in range(15,30*page+15,30):\n",
    "        yield base_url.format(page=i,target_id=target_id,v_id=v_id)\n",
    "\n",
    "def crawl_all(df,num,page,headers):\n",
    "    \"\"\"\n",
    "    爬取弹幕的信息\n",
    "    \"\"\"\n",
    "    df_final=pd.DataFrame()\n",
    "    count=1\n",
    "    for v_id,target_id in zip(df['id'][:num],df['target_id'][:num]):\n",
    "        print(f\"正在爬取第{count}集\")\n",
    "        for url in parse_urls(v_id,target_id,page):\n",
    "            df_one_page=get_one_page_barrage(url,headers)\n",
    "            df_final=pd.concat([df_final,df_one_page])\n",
    "            time.sleep(0.5+random.random())\n",
    "        count+=1\n",
    "    print(\"爬取结束\")\n",
    "    return df_final\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    df_id_mapping=get_all_danmukey()\n",
    "    df_id_mapping.to_csv(\"danmukey.csv\",encoding=\"utf_8_sig\",index=0)\n",
    "    df_data=crawl_all(df_id_mapping,1,5,headers)\n",
    "    df_data.to_csv(\"danmu_data.csv\",encoding=\"utf_8_sig\",index=0)\n",
    "                                              \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
